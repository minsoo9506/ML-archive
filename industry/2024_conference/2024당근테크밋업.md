- https://www.youtube.com/playlist?list=PLaHcMRg2hoBryC2cZkhyEin5MrnEJhMUl
- https://tech-meetup.daangn.com/


## AI: LLM
### [ㅎㅖ어져서 팝니ㄷr ☆: LLM과 임베딩 유사도로 빠르게 패턴을 바꾸는 업자 잡아내기](https://www.youtube.com/watch?v=UGjRhqZygHg&list=PLaHcMRg2hoBryC2cZkhyEin5MrnEJhMUl&index=1)
- 전문판매업자
  - 사업체 보유
  - 대량 생성, 게시글, 채팅 도배
  - 서비스 여러 수치들을 인위적으로 조작
- 기존 해결방안
  - 행위 발생 전
    - 앱 보안정책 강화
    - 비정상 네트워크 트래픽 차단
    - 요청 위변조 탐지, 비정상 동네인증/기기제한
  - 행위 발생 후
    - supervised learning
- supervised learning
  - 사용자 신고를 cs 센터에서 data labeling
  - 발견전까지 학습이 어렵다. 빠르게 바뀌는 패턴에 대응이 어렵다. 판매업자 집단별 패턴이 다양한다.
- 새로운 해결방안
  - 유사컨텐츠 로직, LLM 로직
- 유사 컨텐츠 탐지
  - 컨텐츠 생성 -> embedding 생성 -> Pinecone 에 저장 -> 유사 컨텐츠 찾기
  - 컨텐츠 종류에 따라 다른 Namespace 에 저장하고 Pinecone 내부 로직으로 Namespace 내 임베딩 클러스터링
  - 클러스터링 크기가 커지면 slack 알림 발송, 어드민에서 처리 가능
    - 유사한 글, 그림이 많아지는 경우를 찾을 수 있찌
    - 근데 반대로 어뷰징이 아닌데 아주 많이들 사용되는 이미지도 있어서 자동 신고는 못함
- zero-shot with auto-generated prompt
  - 2 stage (gpt-4o, 40-mini 사용)
    - LLM 에게 일반 사용자 게시글, 전문판매업자 게시글 각 100개를 주면서 특징 뽑도록 함 (프로프트 공개)
      - 특징 요약, 품목&키워드&패턴은 무시, 작문 스타일에 집중, 높은 추상화 레벨
    - 위 결과를 그대로 prompt 에 사용하여 전문판매업자 게시글 탐지
      - true or false 를 결과로 보여주고 이유도 같이
  - ML 모델 보다 빠른 업데이트 주기, 변화에 유연, 라벨링 데이터가 적게 필요
- 결과 측정
  - precision, recall
  - LLM과 유사 컨텐츠 로직으로 해서 더 많은 어뷰징 캐치
  - 유사 컨텐츠 기반은 사람이 최종 결정을 해서 precision 98.7%
  - LLM 로직은 자동화라 69.4%
  - 제대된 계정중 21% 는 LLM, 9.1% 는 유사 컨텐츠

## 추천
### [당근 추천 알고리즘 - 홈피드 후보모델 파헤치기](https://www.youtube.com/watch?v=qYo0R2nv1PQ&list=PLaHcMRg2hoBryC2cZkhyEin5MrnEJhMUl&index=3)
-> 홈피드 추천 뿐만 아니라 범용성 있게 플랫폼의 성격도 있음 (4개국, 4개 지면 하루 10개 이상 학습파이프라인, 600개 이상 추론 파이프라인)
-> 생소하거나 특별한 내용은 없으나 two-tower 모델의 일반적인 process 정석

- how to 홈피드 추천
  - 크게 후보 생성, 랭킹
- 후보 모델
  - two-tower 구조
    - query: 사용자, candidate: 게시글
  - 학습방법
    - contrastive learning
      - query-positive candidate 가깝게, negative 는 멀게 임베딩 학습
- 후보 모델 파이프라인
  - TFX 에 기반한 학습 + 추론 파이프라인
  - 범용성 고려
    - 홈피드 이외의 서비스에서도 적용할 수 있도록
    - 여러 다른 타입의 게시글에도 적용할 수 있도록
    - 사용자, 게시글 모두 query 가 될 수 있도록
  - 편의성
    - 코드에 깊은 이해 없이도 파이프라인 만들 수 있도록
    - 플랫폼 같은 느낌
- training pipieline
  - schema definition -> data preparation -> preprocessing -> training
- schema definition
  - feature
    - 타입, 크기, 필수성여부, 전처리 방법 정의
  - feature group
    - 의미적으로 하나로 묶을 수 있는 feature 들의 group
- data preparation
  - positive example, candidate pool
  - positive example
    - query-cand 간의 positive interaction 이 일어난 pair 에 대해 features 를 붙이는 과정
  - candidate pool
    - 학습, 평가에 사용될 수 있는 candidate 의 집합
- preprocessing
  - group transform -> feature transform
- training
- inference
  - retrieval model
    - query model 로 query embedding 을 뽑고 이와 가까운 cand embedding 으롤 뽑아서 nearest cand 추출
    - ANN 사용
- inference pipeline
  - 후보군 feature 가져오기 -> query, cand model 가져오기 -> cand embedding 구축 -> query model, cand embedding 으로 retrieval model 구축 (ANN 빌드) -> 빌드한 모델을 원격 저장소에 업로드
- 고민했던 것들
  - negative sampling strategy
    - in-batch negative 를 기본적으로 사용
    - 근데 positive 에서만 negative 가 만들어지니까 bias 존재 -> 이를 해결하기 위해 전체데이터에서 random negative 주입
    - hard negative 도 주입: 유저에게 노출되었지만 positive interaction 이 일어나지 않은 경우
      - 추천로직을 타고 있기 때문에 노출되었다는 것은 이미 유저와 어느정도 가깝다는 것을 의미
    - negative mining
      - negative 를 다 사용하는 것도 가능하지만, 각각에서 random 하게 또는 모델이 어려워/쉬워하는 것으로만 학습 가능
  - ANN meets Locality
    - 근처 지역의 게시글만 노출해야함
    - ANN 에서 indexing 은 벡터 간 거리 계산에 최적화, 필터링 조건 추가시 효율성 저하
    - embedding-based filtering
      - region id 를 학습해서 실제 interaction 이 일어난 region 끼리 가깝게 학습
      - 후처리 hard-filtering 을 고려해 넉넉하게 뽑기
    - filtered bruteForce
      - candidate embedding 계산전에 필터링
  - evaluating retrieval model
    - recall@k: 후보군 뽑았을 때, 그 안에 positive 가 몇개?
    - 3단계 evaluation
      - 학습시점: 학습단계에서 batch metric 으로 평가
        - batch 내에서 모델이 positive 를 잘 찾는지 확인
        - 큰 의미는 두지 않고 모델이 잘 학습 되는지 확인용
      - 평가시점: 학습에 나온 전체 데이터중에서 positive 찾기
        - epoch 끝날때 마다 eval dataset 에서 positive 찾기
      - 테스트시점: 시간으로 분리, 학습이 끝난 뒤 retrieval model 구축해서 test dataset 에 대해 평가
- 시도하고 있는 것들
  - sampling bias correction
    - 다양한 데이터셋에서 나온 negative 데이터셋에서 popularity 에 따라 sampling probability 가 달라짐
  - optimizing reward function
    - 1,0 을 넘어서 다양한 reward 고려

### [수십억 개 연결이 존재하는 당근 그래프에서 GNN 학습하기](https://www.youtube.com/watch?v=R7ecb7xKDj0&list=PLaHcMRg2hoBryC2cZkhyEin5MrnEJhMUl&index=7)
- 사용자를 잘 표현하는 유저 임베딩 벡터를 만들자 (배치 추론)
  - 다양한 딥러닝 모델에 적용 가능
  - 더 길고 많은 데이터 활용
- GNN 왜? multi-hop 관계로 더 깊은 연결을 이해하고 유저 표현 가능
- message passing 관련 설명
- Tensorflow GNN 사용, 사용하는 과정 설명 (당근은 tensorflow 환경임)
- 당근 그래프 크기 (90일)
  - 유저 노드 2000만, 게시글 노드 7500만, 엣지 16억
  - 크기가 커서 tensorflow GNN 의 graph sampling algorithm 사용 (분산처리)
- 그래프 정의하기
  - 당근에서는 다양한 유저와 지역기반 컨텐츠와 상호작용 (중고거래, 커뮤니티, 동네 알바, 동네 업체 등등)
  - heterogeneous vs bipartite
    - 연결의 표현, 샘플링, 모델링 측명 고민하고 bipartite 로 결정
- 그래프 학습
  - 유저를 잘 표현하는 것에 집중
  - 별도의 레이블 없이 그래프 내의 연결에 담겨있는 유의미한 패턴 학습
- contrastive learning (pinsage 를 참고 했다고 함)
  - 유사유저?
    - 서비스내에서 행동패턴이 유사한 유저들
    - positive pair는 같은 컨텐츠에 대해 상호작용한 유저들로 사용
      - 근데 가중치가 없고 sparse 함. 같은 컨텐츠라 지역성이 우선적으로 반영됨
      - 그래서 좀 더 추상화된 category 로 대체 했더니 더 좋은 결과가 나옴
  - 현재는 in-batch negative 만 사용
- 기타
  - 엣지 별 가중치를 정의하여 가중치 기반의 샘플링 (pinsage의 importance 기반의 랜덤 워크와 유사)
- 유저 임베딩 적용하기
  - 추천에서 후보 생성시 사용
  - 랭킹 모델에서 feature 로 사용

## 검색
### [중고거래 시멘틱서치 도입기: 꽁꽁 얼어붙은 키워드 위로 벡터가 걸어다닙니다](https://www.youtube.com/watch?v=bWfWFAMbJQ4&list=PLaHcMRg2hoBryC2cZkhyEin5MrnEJhMUl&index=4)
- 검색 단계
  - 검색 대상 문서 DB 에 넣기 (indexing)
  - 검색어 입력이 오면 후보를 찾아옴 (retrieval)
  - 순위 정렬 (ranking)
- 기존에는 키워드 검색 기반
  - 텍스트 간의 일치성기반으로 정보 검색
  - 동의의 사전 등이 중요
  - but 의미적으로 유사한 물품을 검색 x
- 그래서 시멘틱서치 도입
  - 임베딩을 사용한 검색 (embedding-based retrieval)
- 모델 학습
  - two-tower model 사용
  - 검색어와 물품 간의 의미적인 유사성 학습 필요 -> 클릭로그 검색어-물품 데이터 사용
  - 근데 클릭은 노이지하고 양이 많음 -> 채팅기반 검색어-물품 쌍을 데이터셋 사용
    - 클릭의 4% 지만 학습 양상은 유사하고 Facebook 에서도 채팅 기반 데이터셋 사용했다고 함 (Que2Search, KDD2021)
- 근데 롱테일 검색어의 성능이 매우 떨어짐
  - 불충분한 채팅 데이터
  - 임베딩 모델의 사전 지식에 의존 불가
- 임베딩 모델이 잘 모르는 검색어 파악하기
  - Fuzzy match 로직으로 검색어 마다 부적절 물품비율을 확인해서 비율이 높으면 클릭 데이터로 추가 학습 진행
- 모델 평가하기
  - retrieval 모델을 평가하려면 라벨이 있으면 좋다. 근데 현실적으로 어렵다.
  - 클릭데이터를 활용할 수 있지만 정확한 라벨이라고 볼 수 없다. (특히, 잘했는데 미클릭한 경우)
- 라벨링 가이드라인
  - 검색어 유형 분류 (Brand, Product, Item, Attribute)
  - 질의 의도 파악 (Product > Brand > Item > Attribute)
    - 위 검색어 유형에서 순서대로 core 의도, minor 의도 구분
  - 점수 체계
    - 둘다 맞으면 2점, core 만 맞으면 1점, core 가 틀리거나 두 개 이상의 minor 틀리면 0점
- 5000개의 human label 확보 -> 부족하다 -> 유사한 결과를 얻을 수 있게 LLM 프롬프트 튜닝
  - 프롬프트 효과 있었던 부분
    - 추론 과정을 출력, 영어로 프롬프트 작성, 코드 형식의 가이드, 다양한 예시

## Platform
### [당근페이 데이터플랫폼 구축기](https://www.youtube.com/watch?v=abdIqj9dxww&list=PLaHcMRg2hoBryC2cZkhyEin5MrnEJhMUl&index=2)
### [지표 통합과 탐색: KarrotMetrics와 Explorer로 가치 있는 의사결정하기](https://www.youtube.com/watch?v=I_i3jbQn_tg&list=PLaHcMRg2hoBryC2cZkhyEin5MrnEJhMUl&index=5)
### [추천 서빙 시스템 아키텍처: 높은 생산성을 위한 아키텍쳐 및 ML Flywheel](https://www.youtube.com/watch?v=Cs09fzdJo5Y&list=PLaHcMRg2hoBryC2cZkhyEin5MrnEJhMUl&index=6)
### [온콜, 알림만 보다가 죽겠어요](https://www.youtube.com/watch?v=4XpZpplWJBw&list=PLaHcMRg2hoBryC2cZkhyEin5MrnEJhMUl&index=8)